# ğŸ§  Crypto Market ETL Pipeline with Dagster, MinIO & Docker

A professional, production-grade **data engineering project** that demonstrates end-to-end ETL pipeline design using **Dagster**, **MinIO (S3-compatible object store)**, and **Docker**.

This project extracts structured crypto market data from the **CoinGecko API**, performs cleansing and transformation, and stores the processed data as **Parquet files in MinIO**.

---

## ğŸš€ Features

- âœ… Modular, scalable, and professional pipeline design
- ğŸ§± **ETL Pipeline**: Extract â†’ Transform â†’ Load
- ğŸ•¹ï¸ **Dagster** for orchestration, manual + scheduled jobs
- ğŸª£ **MinIO** for object storage (S3 replacement)
- ğŸ³ **Dockerized** for portability and reproducibility
- ğŸ› ï¸ **CI/CD-ready** structure (GitHub Actions pipeline coming soon)
- ğŸ“‚ Clean and structured Python codebase with logging, config management, and `.env` usage

---

## ğŸ§© Tech Stack

| Component         | Tech Used                       |
|------------------|----------------------------------|
| Orchestration     | [Dagster](https://dagster.io/)   |
| Object Storage    | [MinIO](https://min.io/)         |
| API Source        | [CoinGecko](https://coingecko.com/) |
| File Format       | Parquet via `pyarrow`            |
| DevOps            | Docker, Git, GitHub              |
| Logging & Config  | Python `logging`, `dotenv`       |

---

## ğŸ“ Project Structure

dagster_crypto_etl_pipeline/
â”œâ”€â”€ dagster_pipeline/ 
â”‚ â”œâ”€â”€ job.py
â”‚ â”œâ”€â”€ schedules.py
â”‚ â””â”€â”€ definitions.py
â”œâ”€â”€ src/ 
â”‚ â”œâ”€â”€ extract/ 
â”‚ â”œâ”€â”€ transform/ 
â”‚ â”œâ”€â”€ load/ 
â”‚ â”œâ”€â”€ config/ 
â”‚ â””â”€â”€ utils/ 
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ dagster.yaml 


## âš™ï¸ How It Works

### 1. Extract

- Uses `requests` to pull paginated crypto market data from CoinGecko's `/coins/markets` API.
- Respects rate limits using `sleep`.

### 2. Transform

- Cleans the raw data, removes nulls, selects relevant columns.
- Applies a mock **USD to INR conversion**, filters by market cap, adds timestamps.

### 3. Load

- Writes the transformed DataFrame as **Parquet** to MinIO using `s3fs` and `pyarrow`.
- S3 paths are dynamically timestamped for each run.

---

## ğŸ§ª Run the Pipeline

### â–¶ï¸ Manually (Local)

dagster dev

### â–¶ï¸ Automatically (Scheduled)

dagster-daemon run

